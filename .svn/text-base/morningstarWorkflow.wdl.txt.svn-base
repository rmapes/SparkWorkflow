workflow {
	properties = loadProperties("morningstar.workflow.properties");

	jmxtrigger.add(morningstarDailyLoad);

	def job morningstarDailyLoad() {
		filenames = morningstarDispatcher(properties.dailyDownloadDirectory);
		morningstarLoaderPipeline(*filenames, properties.dailyDownloadDirectory);
	}

	def job morningstarDispatcher(dailyDownloadDirectory){
		filenames = runCommand("ls ${dailyDownloadDirectory}");
		return split(filenames);
	}

	def job morningstarLoaderPipeline(filename, dailyDownloadDirectory) {
		morningstarArchiveDirectory = properties.morningstarArchiveDirectory;
		stagingSuffix = convertFilenameToStagingSuffix(filename);
		morningstarLoadToStaging(stagingSuffix, filename);
		morningstarMigrateStagingToProduction" />
		archiveFile(${dailyDownloadDirectory, ${morningstarArchiveDirectory});
	}

	def job convertFilenameToStagingSuffix(filename) {
		return filename; // TODO: add transform to staging suffix
	}

	def job morningstarLoadToStaging(stagingSuffix, filename) : dbRoot=properties.dbRoot, dbNode=*[1-4] {
		loaderHome = properties.loaderHome;
		dailyDownloadDirectory = properties.dailyDownloadDirectory;
		transforms = "morningstarStatic futuresTrades futureOrders";
		runCommand("zcat ${dailyDownloadDirectory}/${filename} | ${loaderHome}/bin/datamigrator -n ${dbRoot}{dbNode} -s ${stagingSuffix} ${transforms}");
	}

	def job morningstarMigrateStagingToProduction(stagingSuffix) : dbRoot=properties.dbRoot, dbNode=*[1-4] {
		loaderHome = properties.loaderHome;
		transforms = "morningstarStatic futuresTrades futureOrders";
		runCommand("${loaderHome}/bin/dataloader -n ${dbRoot}{dbNode} -s ${stagingSuffix} ${transforms}");
	}

	def job archiveFile(fromDirectory, toDirectory, filename) {
		runCommand("mv ${fromDirectory}/${filename} ${toDirectory}/${filename}");
	}
}
